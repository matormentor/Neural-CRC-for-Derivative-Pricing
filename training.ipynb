{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ccf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor, StochasticWeightAveraging\n",
    "\n",
    "import app.training.networks as net\n",
    "from app.training.dataset.data_module import IVS_DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6bec6a",
   "metadata": {},
   "source": [
    "# NN1 Residual Feed Forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee14dbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17604), started 10:34:12 ago. (Use '!kill 17604' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c0913d79ded4fa66\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c0913d79ded4fa66\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9b7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (600_000, 42)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>r</th><th>q</th><th>v0</th><th>kappa</th><th>theta</th><th>sigma</th><th>rho</th><th>lambda_p</th><th>tau_1</th><th>tau_2</th><th>tau_3</th><th>tau_4</th><th>tau_5</th><th>tau_6</th><th>tau_7</th><th>tau_8</th><th>tau_9</th><th>tau_10</th><th>m_1</th><th>m_2</th><th>m_3</th><th>m_4</th><th>m_5</th><th>m_6</th><th>m_7</th><th>m_8</th><th>m_9</th><th>m_10</th><th>m_11</th><th>m_12</th><th>m_13</th><th>nu_1</th><th>nu_2</th><th>nu_3</th><th>nu_4</th><th>nu_5</th><th>delta_1</th><th>delta_2</th><th>delta_3</th><th>delta_4</th><th>delta_5</th><th>implied_vol_surface</th></tr><tr><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i16</td><td>i16</td><td>i16</td><td>i16</td><td>i16</td><td>i16</td><td>i16</td><td>i16</td><td>i16</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>list[f32]</td></tr></thead><tbody><tr><td>0.042819</td><td>0.02408</td><td>0.075004</td><td>9.563508</td><td>0.234728</td><td>1.410849</td><td>-0.050167</td><td>0.221455</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>-0.06145</td><td>-0.261182</td><td>0.014085</td><td>0.040484</td><td>0.226299</td><td>0.231427</td><td>0.243308</td><td>0.203859</td><td>0.250898</td><td>0.209558</td><td>[0.551366, 0.474349, … 0.488375]</td></tr><tr><td>0.047914</td><td>0.021959</td><td>0.059782</td><td>6.615184</td><td>0.338144</td><td>0.527069</td><td>-0.122137</td><td>0.218679</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>0.251862</td><td>-0.084615</td><td>0.099564</td><td>0.127918</td><td>-0.013492</td><td>0.223936</td><td>0.205652</td><td>0.203066</td><td>0.264801</td><td>0.205546</td><td>[0.703693, 0.609873, … 0.566131]</td></tr><tr><td>0.04352</td><td>0.00934</td><td>0.045393</td><td>9.307867</td><td>0.145592</td><td>1.447328</td><td>0.018445</td><td>0.448545</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>0.158138</td><td>0.203891</td><td>-0.026683</td><td>-0.095697</td><td>0.107908</td><td>0.251708</td><td>0.269171</td><td>0.277242</td><td>0.204776</td><td>0.227962</td><td>[0.738972, 0.645014, … 0.399378]</td></tr><tr><td>0.034193</td><td>0.012755</td><td>0.082381</td><td>8.083626</td><td>0.12598</td><td>0.529315</td><td>0.250438</td><td>0.364253</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>0.186329</td><td>-0.143617</td><td>0.104117</td><td>-0.20423</td><td>0.255101</td><td>0.272728</td><td>0.297045</td><td>0.237253</td><td>0.258477</td><td>0.240227</td><td>[0.74685, 0.649684, … 0.404359]</td></tr><tr><td>0.041095</td><td>0.028444</td><td>0.066657</td><td>9.0394</td><td>0.292203</td><td>0.423733</td><td>-0.001932</td><td>0.351646</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>0.167266</td><td>-0.21599</td><td>0.132366</td><td>-0.011974</td><td>0.124185</td><td>0.247581</td><td>0.278154</td><td>0.215618</td><td>0.247202</td><td>0.211566</td><td>[0.716889, 0.623773, … 0.538575]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0.021236</td><td>0.010544</td><td>0.08991</td><td>6.869073</td><td>0.332751</td><td>1.178937</td><td>-0.010981</td><td>0.277244</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>0.061865</td><td>-0.014683</td><td>0.000728</td><td>0.094775</td><td>0.155623</td><td>0.277628</td><td>0.208675</td><td>0.27168</td><td>0.278489</td><td>0.218587</td><td>[0.656443, 0.5669, … 0.567817]</td></tr><tr><td>0.014792</td><td>0.00726</td><td>0.068549</td><td>6.734044</td><td>0.119505</td><td>0.533739</td><td>-0.020346</td><td>0.178137</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>-0.050293</td><td>-0.278203</td><td>0.230263</td><td>-0.001027</td><td>-0.09365</td><td>0.218623</td><td>0.214988</td><td>0.264861</td><td>0.273286</td><td>0.2186</td><td>[0.53584, 0.460477, … 0.346909]</td></tr><tr><td>0.039311</td><td>0.01098</td><td>0.101494</td><td>6.134017</td><td>0.230201</td><td>1.154013</td><td>-0.220341</td><td>0.227497</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>-0.083854</td><td>0.019652</td><td>-0.077777</td><td>-0.280855</td><td>-0.286169</td><td>0.209684</td><td>0.207535</td><td>0.281355</td><td>0.289655</td><td>0.292383</td><td>[0.524997, 0.452119, … 0.4888]</td></tr><tr><td>0.03715</td><td>0.005737</td><td>0.102898</td><td>9.643427</td><td>0.143445</td><td>1.36571</td><td>0.214853</td><td>0.210974</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>-0.254219</td><td>0.291229</td><td>0.286057</td><td>0.196834</td><td>-0.282683</td><td>0.274672</td><td>0.292174</td><td>0.245819</td><td>0.211792</td><td>0.250706</td><td>[0.506658, 0.436637, … 0.397489]</td></tr><tr><td>0.019557</td><td>0.024456</td><td>0.020295</td><td>5.507356</td><td>0.204017</td><td>0.278534</td><td>-0.274688</td><td>0.382638</td><td>7</td><td>11</td><td>17</td><td>27</td><td>44</td><td>69</td><td>110</td><td>175</td><td>277</td><td>440</td><td>0.8</td><td>0.833333</td><td>0.866667</td><td>0.9</td><td>0.933333</td><td>0.966667</td><td>1.0</td><td>1.033333</td><td>1.066667</td><td>1.1</td><td>1.133333</td><td>1.166667</td><td>1.2</td><td>0.179468</td><td>-0.255105</td><td>0.009437</td><td>0.022432</td><td>0.000015</td><td>0.286725</td><td>0.206712</td><td>0.250969</td><td>0.269774</td><td>0.286722</td><td>[0.757213, 0.658997, … 0.452551]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (600_000, 42)\n",
       "┌──────────┬──────────┬──────────┬──────────┬───┬──────────┬──────────┬──────────┬─────────────────┐\n",
       "│ r        ┆ q        ┆ v0       ┆ kappa    ┆ … ┆ delta_3  ┆ delta_4  ┆ delta_5  ┆ implied_vol_sur │\n",
       "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---      ┆ ---      ┆ ---      ┆ face            │\n",
       "│ f32      ┆ f32      ┆ f32      ┆ f32      ┆   ┆ f32      ┆ f32      ┆ f32      ┆ ---             │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ list[f32]       │\n",
       "╞══════════╪══════════╪══════════╪══════════╪═══╪══════════╪══════════╪══════════╪═════════════════╡\n",
       "│ 0.042819 ┆ 0.02408  ┆ 0.075004 ┆ 9.563508 ┆ … ┆ 0.203859 ┆ 0.250898 ┆ 0.209558 ┆ [0.551366,      │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.474349, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.48837…        │\n",
       "│ 0.047914 ┆ 0.021959 ┆ 0.059782 ┆ 6.615184 ┆ … ┆ 0.203066 ┆ 0.264801 ┆ 0.205546 ┆ [0.703693,      │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.609873, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.56613…        │\n",
       "│ 0.04352  ┆ 0.00934  ┆ 0.045393 ┆ 9.307867 ┆ … ┆ 0.277242 ┆ 0.204776 ┆ 0.227962 ┆ [0.738972,      │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.645014, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.39937…        │\n",
       "│ 0.034193 ┆ 0.012755 ┆ 0.082381 ┆ 8.083626 ┆ … ┆ 0.237253 ┆ 0.258477 ┆ 0.240227 ┆ [0.74685,       │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.649684, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.404359…       │\n",
       "│ 0.041095 ┆ 0.028444 ┆ 0.066657 ┆ 9.0394   ┆ … ┆ 0.215618 ┆ 0.247202 ┆ 0.211566 ┆ [0.716889,      │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.623773, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.53857…        │\n",
       "│ …        ┆ …        ┆ …        ┆ …        ┆ … ┆ …        ┆ …        ┆ …        ┆ …               │\n",
       "│ 0.021236 ┆ 0.010544 ┆ 0.08991  ┆ 6.869073 ┆ … ┆ 0.27168  ┆ 0.278489 ┆ 0.218587 ┆ [0.656443,      │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.5669, …       │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.567817]       │\n",
       "│ 0.014792 ┆ 0.00726  ┆ 0.068549 ┆ 6.734044 ┆ … ┆ 0.264861 ┆ 0.273286 ┆ 0.2186   ┆ [0.53584,       │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.460477, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.346909…       │\n",
       "│ 0.039311 ┆ 0.01098  ┆ 0.101494 ┆ 6.134017 ┆ … ┆ 0.281355 ┆ 0.289655 ┆ 0.292383 ┆ [0.524997,      │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.452119, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.4888]         │\n",
       "│ 0.03715  ┆ 0.005737 ┆ 0.102898 ┆ 9.643427 ┆ … ┆ 0.245819 ┆ 0.211792 ┆ 0.250706 ┆ [0.506658,      │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.436637, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.39748…        │\n",
       "│ 0.019557 ┆ 0.024456 ┆ 0.020295 ┆ 5.507356 ┆ … ┆ 0.250969 ┆ 0.269774 ┆ 0.286722 ┆ [0.757213,      │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.658997, …     │\n",
       "│          ┆          ┆          ┆          ┆   ┆          ┆          ┆          ┆ 0.45255…        │\n",
       "└──────────┴──────────┴──────────┴──────────┴───┴──────────┴──────────┴──────────┴─────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader = IVS_DataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a8e3c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | mse_loss              | MSELoss    | 0      | train\n",
      "1 | r2Score               | R2Score    | 0      | train\n",
      "2 | activation            | ELU        | 0      | train\n",
      "3 | input_head            | Sequential | 43.0 K | train\n",
      "4 | hidden_residual_block | Sequential | 4.2 M  | train\n",
      "5 | output_layer          | Linear     | 133 K  | train\n",
      "-------------------------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.499    Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e92ed32281e48878a6ecafb89737c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbf117cc9d4407dad02a992eafd1aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    570\u001b[0m     ckpt_path,\n\u001b[0;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:271\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    270\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_output, batch, batch_idx)\n\u001b[1;32m--> 271\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logger_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:203\u001b[0m, in \u001b[0;36m_LoggerConnector.on_batch_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_loop_iter, \u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m--> 203\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress_bar_metrics\u001b[38;5;241m.\u001b[39mupdate(metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:234\u001b[0m, in \u001b[0;36m_LoggerConnector.metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:490\u001b[0m, in \u001b[0;36m_ResultCollection.metrics\u001b[1;34m(self, on_step)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result_metric\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mprog_bar:\n\u001b[1;32m--> 490\u001b[0m         metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m][forked_name] \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_tensors_to_scalars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\lightning_fabric\\utilities\\apply_func.py:136\u001b[0m, in \u001b[0;36mconvert_tensors_to_scalars\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_item\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\lightning_utilities\\core\\apply_func.py:64\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype):  \u001b[38;5;66;03m# single element\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\lightning_fabric\\utilities\\apply_func.py:134\u001b[0m, in \u001b[0;36mconvert_tensors_to_scalars.<locals>.to_item\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe metric `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` does not contain a single element, thus it cannot be converted to a scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m     )\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m\n\u001b[0;32m     20\u001b[0m lr_monitor \u001b[38;5;241m=\u001b[39m LearningRateMonitor(logging_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     23\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping_callback, checkpoint_callback, lr_monitor, stochastic_weight_avg], \n\u001b[0;32m     24\u001b[0m                     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[0;32m     25\u001b[0m                     deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "nn1 = net.NN1Residual()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    "    filename=\"best_model-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "stochastic_weight_avg = StochasticWeightAveraging(1e-3)\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "trainer = L.Trainer(accelerator='gpu', \n",
    "                    callbacks=[early_stopping_callback, checkpoint_callback, lr_monitor, stochastic_weight_avg], \n",
    "                    max_epochs=20, \n",
    "                    deterministic=True)\n",
    "\n",
    "trainer.fit(nn1, DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec39e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84986f149d02446dbe0839495129a9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      " adj_test_r2_score_epoch    0.42912957072257996\n",
      "        test_loss          0.0020858978386968374\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0020858978386968374,\n",
       "  'adj_test_r2_score_epoch': 0.42912957072257996}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(nn1, DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2 = net.NN2()\n",
    "\n",
    "dummy_input = torch.randn(1, 133)\n",
    "nn2.eval()\n",
    "output = nn2(dummy_input)\n",
    "print(\"Output shape:\", output.shape)  # Should be (1, 10)\n",
    "assert output.shape == (1, 10)\n",
    "print(nn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13110af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate networks\n",
    "nn1 = net.NN1Residual()\n",
    "nn2 = net.NN2()\n",
    "nn3 = net.NN3(nn1, nn2)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(nn3.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f625555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for NN3\n",
    "def train_nn3(nn3, optimizer, criterion, train_params, target_params, epochs=50, batch_size=64):\n",
    "    num_batches = len(train_params) // batch_size\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for i in range(num_batches):\n",
    "            # Extract batch data\n",
    "            batch_params = train_params[i * batch_size:(i + 1) * batch_size]\n",
    "            batch_target = target_params[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = nn3(batch_params)\n",
    "            loss = criterion(outputs, batch_target)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / num_batches:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Train the network\n",
    "train_nn3(nn3, optimizer, criterion, train_params, train_params, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def test_nn3(nn3, test_params, test_target):\n",
    "    nn3.eval()  # Set to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predictions = nn3(test_params)\n",
    "        loss = criterion(predictions, test_target)\n",
    "    print(f\"Test Loss: {loss.item():.4f}\")\n",
    "    # print(f\"Accuracy: {accuracy_score(predictions, test_target):.4f}\")\n",
    "\n",
    "# Test the network\n",
    "test_nn3(nn3, test_params, test_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
