{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ccf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor, StochasticWeightAveraging\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import app.training.networks as net\n",
    "\n",
    "from app.training.dataset import IVS_DataModule, DualInput_IVS_DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6bec6a",
   "metadata": {},
   "source": [
    "# NN1 Residual Feed Forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee14dbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 3476), started 5:13:26 ago. (Use '!kill 3476' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-77dc398126ade6f3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-77dc398126ade6f3\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df9b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader_NN1 = IVS_DataModule()\n",
    "DataLoader_NN3 = DualInput_IVS_DataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f2313",
   "metadata": {},
   "source": [
    "# Learning Rate Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e7b64",
   "metadata": {},
   "source": [
    "### NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a392203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "Finding best initial lr:  42%|████▏     | 211/500 [00:06<00:07, 36.32it/s]\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    571\u001b[0m     ckpt_path,\n\u001b[0;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:962\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[1;32m--> 962\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_fit_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    963\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:222\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[1;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 222\u001b[0m             fn(trainer, trainer\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\callbacks\\lr_finder.py:130\u001b[0m, in \u001b[0;36mLearningRateFinder.on_fit_start\u001b[1;34m(self, trainer, pl_module)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_fit_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\callbacks\\lr_finder.py:113\u001b[0m, in \u001b[0;36mLearningRateFinder.lr_find\u001b[1;34m(self, trainer, pl_module)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_lr \u001b[38;5;241m=\u001b[39m \u001b[43m_lr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_training_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_early_stop_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdate_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattr_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attr_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_exit:\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\tuner\\lr_finder.py:278\u001b[0m, in \u001b[0;36m_lr_find\u001b[1;34m(trainer, model, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Fit, lr & loss logged in callback\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m \u001b[43m_try_loop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Prompt if we stopped early\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\tuner\\lr_finder.py:523\u001b[0m, in \u001b[0;36m_try_loop_run\u001b[1;34m(trainer, params)\u001b[0m\n\u001b[0;32m    522\u001b[0m loop\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:339\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m--> 339\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_batch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_output, batch, batch_idx)\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:222\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[1;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 222\u001b[0m             fn(trainer, trainer\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\tuner\\lr_finder.py:419\u001b[0m, in \u001b[0;36m_LRCallback.on_train_batch_end\u001b[1;34m(self, trainer, pl_module, outputs, batch, batch_idx)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m loss_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m current_step \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mglobal_step\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Use lr_find to identify the optimal learning rate\u001b[39;00m\n\u001b[0;32m     30\u001b[0m tuner \u001b[38;5;241m=\u001b[39m Tuner(trainer)\n\u001b[1;32m---> 31\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m lr_finder \u001b[38;5;66;03m# lr_finder not NONE\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Plot the learning rate finder results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\tuner\\tuning.py:180\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[0;32m    177\u001b[0m lr_finder_callback\u001b[38;5;241m.\u001b[39m_early_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [lr_finder_callback] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lr_finder_callback]\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lr_finder_callback\u001b[38;5;241m.\u001b[39moptimal_lr\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "model = net.NN1Residual()\n",
    "\n",
    "# Instantiate the DataModule\n",
    "data_module = IVS_DataModule()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    "    filename=\"best_model-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "stochastic_weight_avg = StochasticWeightAveraging(1e-3)\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# Define a Trainer\n",
    "trainer = L.Trainer(callbacks=[early_stopping_callback, lr_monitor, stochastic_weight_avg], \n",
    "                    max_epochs=1)  # We only need one epoch for `lr_find`\n",
    "\n",
    "# Use lr_find to identify the optimal learning rate\n",
    "tuner = Tuner(trainer)\n",
    "lr_finder = tuner.lr_find(model, datamodule=data_module, max_lr=4e-3, num_training=500)\n",
    "assert lr_finder # lr_finder not NONE\n",
    "\n",
    "# Plot the learning rate finder results\n",
    "fig = lr_finder.plot(suggest=True, show=True)\n",
    "\n",
    "# Retrieve the suggested learning rate\n",
    "optimal_lr = lr_finder.suggestion()\n",
    "print(f\"Suggested learning rate: {optimal_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30309fc2",
   "metadata": {},
   "source": [
    "### NN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acb1a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\jit\\_trace.py:1304: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%tensor.3 : Float(1024, 41, strides=[41, 1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.1, %100, %101, %102) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:518:0\n",
      "\t%119 : Float(1024, strides=[1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.5, %116, %117, %118) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:17:0\n",
      "\t%tensor.9 : Float(1024, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.7, %164, %165, %166) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:518:0\n",
      "\t%183 : Float(1024, strides=[1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.11, %180, %181, %182) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:17:0\n",
      "\t%tensor.15 : Float(1024, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.13, %228, %229, %230) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:518:0\n",
      "\t%247 : Float(1024, strides=[1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.17, %244, %245, %246) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:17:0\n",
      "\t%tensor.21 : Float(1024, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.19, %292, %293, %294) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:518:0\n",
      "\t%311 : Float(1024, strides=[1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.23, %308, %309, %310) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:17:0\n",
      "\t%tensor.27 : Float(1024, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.25, %356, %357, %358) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:518:0\n",
      "\t%375 : Float(1024, strides=[1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.29, %372, %373, %374) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:17:0\n",
      "\t%tensor.33 : Float(130, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = aten::uniform_(%tensor.31, %422, %423, %424) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:518:0\n",
      "\t%441 : Float(130, strides=[1], requires_grad=1, device=cpu) = aten::uniform_(%tensor, %438, %439, %440) # c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\nn\\init.py:17:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  _check_trace(\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv-math\\lib\\site-packages\\torch\\jit\\_trace.py:1304: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 130 / 130 (100.0%)\n",
      "Greatest absolute difference: 0.4921930879354477 at index (35,) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 104.96288191752772 at index (4,) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# nn1 = net.NN1Residual.load_from_checkpoint(\"lightning_logs\\\\version_33\\\\checkpoints\\\\best_model-epoch=141-val_loss=0.00.ckpt\")\n",
    "nn1 = net.NN1Residual()\n",
    "nn2 = net.NN2()\n",
    "model = net.NN3(nn1=nn1, nn2=nn2)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    "    filename=\"best_model-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "stochastic_weight_avg = StochasticWeightAveraging(1e-3)\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# Define a Trainer\n",
    "trainer = L.Trainer(callbacks=[early_stopping_callback, lr_monitor, stochastic_weight_avg], \n",
    "                    max_epochs=1)  # We only need one epoch for `lr_find`\n",
    "\n",
    "DataLoader_NN3.prepare_data()\n",
    "DataLoader_NN3.setup()\n",
    "DataLoader_NN1.prepare_data()\n",
    "DataLoader_NN1.setup()\n",
    "\n",
    "sample_input1, sample_input2, _ = DataLoader_NN3.dataset[0]  # Extract inputs\n",
    "sample_input1 = sample_input1.unsqueeze(0)  # Add batch dimension\n",
    "sample_input2 = sample_input2.unsqueeze(0)\n",
    "input1, _ = DataLoader_NN1.dataset[0]\n",
    "# writer.add_graph(model, (sample_input1, sample_input2), use_strict_trace=False)\n",
    "writer.add_graph(nn1, input1, use_strict_trace=False)\n",
    "# writer.add_graph(nn2, sample_input1, use_strict_trace=False)\n",
    "\n",
    "# # Use lr_find to identify the optimal learning rate\n",
    "# tuner = Tuner(trainer)\n",
    "# lr_finder = tuner.lr_find(model, datamodule=DataLoader_NN3, min_lr=1e-3, max_lr=1, num_training=1000)\n",
    "# assert lr_finder # lr_finder not NONE\n",
    "\n",
    "# # Plot the learning rate finder results\n",
    "# fig = lr_finder.plot(suggest=True, show=True)\n",
    "\n",
    "# # Retrieve the suggested learning rate\n",
    "# optimal_lr = lr_finder.suggestion()\n",
    "# print(f\"Suggested learning rate: {optimal_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c5dc9",
   "metadata": {},
   "source": [
    "# Training NN1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf8f8b",
   "metadata": {},
   "source": [
    "### SetUp Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4f14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger for Model 1\n",
    "logger_nn1 = TensorBoardLogger(\n",
    "    save_dir=\"lightning_logs\",\n",
    "    name=\"nn1\",\n",
    ")\n",
    "\n",
    "# Logger for Model 2\n",
    "logger_nn3 = TensorBoardLogger(\n",
    "    save_dir=\"lightning_logs\",\n",
    "    name=\"nn3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d07d6",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178c6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    "    filename=\"best_model-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    mode=\"min\",\n",
    "    check_on_train_epoch_end=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "stochastic_weight_avg = StochasticWeightAveraging(1e-3)\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d94797",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f60e1",
   "metadata": {},
   "source": [
    "##### NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e3c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "nn1 = net.NN1Residual(lr=1.2e-05)\n",
    "\n",
    "trainer = L.Trainer(accelerator='gpu', \n",
    "                    callbacks=[early_stopping_callback, checkpoint_callback, lr_monitor, stochastic_weight_avg], \n",
    "                    max_epochs=200)\n",
    "\n",
    "trainer.fit(nn1, DataLoader_NN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1be87",
   "metadata": {},
   "source": [
    "##### NN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dad8e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if NN1 is not trainable\n",
      "Check Passed\n"
     ]
    }
   ],
   "source": [
    "model = net.NN1Residual.load_from_checkpoint(\"lightning_logs\\\\version_33\\\\checkpoints\\\\best_model-epoch=141-val_loss=0.00.ckpt\")\n",
    "nn3_lr = 0.003819442708400466\n",
    "nn3 = net.NN3(model, net.NN2(lr=nn3_lr), lr=nn3_lr)\n",
    "\n",
    "# Assure that nn1 is not trainable\n",
    "print(\"Checking if NN1 is not trainable\")\n",
    "for name, param in nn3.nn1.named_parameters():\n",
    "    # print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "    assert param.requires_grad == False, f\"Parameters in NN1 module {name} shant be trainable\"\n",
    "print(\"Check Passed\")\n",
    "    \n",
    "\n",
    "trainer = L.Trainer(logger=logger_nn3,\n",
    "                    accelerator='gpu', \n",
    "                    callbacks=[early_stopping_callback, checkpoint_callback, lr_monitor, stochastic_weight_avg], \n",
    "                    max_epochs=200)\n",
    "\n",
    "trainer.fit(nn3, DataLoader_NN3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cdc9f0",
   "metadata": {},
   "source": [
    "# Testing NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd2ff678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dim': 41, 'hidden_dim': 1024, 'output_dim': 130, 'lr': 1.2e-05}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net.NN1Residual.load_from_checkpoint(\"lightning_logs\\\\version_33\\\\checkpoints\\\\best_model-epoch=141-val_loss=0.00.ckpt\")\n",
    "checkpoint = torch.load(\"lightning_logs\\\\version_33\\\\checkpoints\\\\best_model-epoch=141-val_loss=0.00.ckpt\", map_location=lambda storage, loc: storage, weights_only=False)\n",
    "checkpoint['hyper_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec39e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da8aeb5d0b34e3dba3965ed6ca5ec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      " adj_test_r2_score_epoch    0.9184309244155884\n",
      "        test_loss         0.00029913688194938004\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.00029913688194938004,\n",
       "  'adj_test_r2_score_epoch': 0.9184309244155884}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, DataLoader_NN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bee8e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['nn1.input_head.0.weight', 'nn1.input_head.0.bias', 'nn1.hidden_residual_block.0.weight', 'nn1.hidden_residual_block.0.bias', 'nn1.hidden_residual_block.2.weight', 'nn1.hidden_residual_block.2.bias', 'nn1.hidden_residual_block.4.weight', 'nn1.hidden_residual_block.4.bias', 'nn1.hidden_residual_block.6.weight', 'nn1.hidden_residual_block.6.bias', 'nn1.output_layer.weight', 'nn1.output_layer.bias', 'nn2.input_head.0.weight', 'nn2.input_head.0.bias', 'nn2.input_head.1.weight', 'nn2.input_head.1.bias', 'nn2.input_head.1.running_mean', 'nn2.input_head.1.running_var', 'nn2.input_head.1.num_batches_tracked', 'nn2.hidden_residual_block.0.weight', 'nn2.hidden_residual_block.0.bias', 'nn2.hidden_residual_block.1.weight', 'nn2.hidden_residual_block.1.bias', 'nn2.hidden_residual_block.1.running_mean', 'nn2.hidden_residual_block.1.running_var', 'nn2.hidden_residual_block.1.num_batches_tracked', 'nn2.hidden_residual_block.3.weight', 'nn2.hidden_residual_block.3.bias', 'nn2.hidden_residual_block.4.weight', 'nn2.hidden_residual_block.4.bias', 'nn2.hidden_residual_block.4.running_mean', 'nn2.hidden_residual_block.4.running_var', 'nn2.hidden_residual_block.4.num_batches_tracked', 'nn2.hidden_residual_block.6.weight', 'nn2.hidden_residual_block.6.bias', 'nn2.hidden_residual_block.7.weight', 'nn2.hidden_residual_block.7.bias', 'nn2.hidden_residual_block.7.running_mean', 'nn2.hidden_residual_block.7.running_var', 'nn2.hidden_residual_block.7.num_batches_tracked', 'nn2.hidden_residual_block.9.weight', 'nn2.hidden_residual_block.9.bias', 'nn2.hidden_residual_block.10.weight', 'nn2.hidden_residual_block.10.bias', 'nn2.hidden_residual_block.10.running_mean', 'nn2.hidden_residual_block.10.running_var', 'nn2.hidden_residual_block.10.num_batches_tracked', 'nn2.output_layer1.weight', 'nn2.output_layer1.bias', 'nn2.batch_norm2.weight', 'nn2.batch_norm2.bias', 'nn2.batch_norm2.running_mean', 'nn2.batch_norm2.running_var', 'nn2.batch_norm2.num_batches_tracked', 'nn2.nu_layer.0.weight', 'nn2.nu_layer.0.bias', 'nn2.delta_layer.0.weight', 'nn2.delta_layer.0.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn3 = net.NN3.load_from_checkpoint(\"lightning_logs\\\\nn3\\\\version_3\\\\checkpoints\\\\best_model-epoch=22-val_loss=0.00.ckpt\", nn1=net.NN1Residual(), nn2=net.NN2())\n",
    "checkpoint = torch.load(\"lightning_logs\\\\nn3\\\\version_3\\\\checkpoints\\\\best_model-epoch=22-val_loss=0.00.ckpt\", map_location=lambda storage, loc: storage, weights_only=False)\n",
    "checkpoint[\"state_dict\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ddab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn3.nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d44753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\USUARIO\\PycharmProjects\\MathThesis\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c07ab2cfefa424b85db149df563f9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      " adj_test_r2_score_epoch     0.616227388381958\n",
      "   nn3_test_loss_epoch     0.0013556694611907005\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'nn3_test_loss_epoch': 0.0013556694611907005,\n",
       "  'adj_test_r2_score_epoch': 0.616227388381958}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(nn3, DataLoader_NN3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
